{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1f90e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4,6\"\n",
    "\n",
    "# 检查CUDA支持并设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载模型和分词器，将模型转移到设备\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-chinese')\n",
    "model = BertModel.from_pretrained('./bert-base-chinese').to(device)\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 获取文本的BERT嵌入\n",
    "def get_batch_embedding(texts, model, tokenizer):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].detach()\n",
    "\n",
    "# 读取和预处理数据\n",
    "with open('documents.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "text = ''.join(data)\n",
    "text = \"\".join(re.findall('[\\u4e00-\\u9fa5]+', text, re.S))\n",
    "\n",
    "# 分词处理\n",
    "words_in_long_text = list(set(jieba.cut(text)))  # 使用集合去重\n",
    "\n",
    "# 计算相似度\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity(embedding1.cpu().numpy(), embedding2.cpu().numpy())[0][0]\n",
    "\n",
    "# 输入词语和长文本\n",
    "input_words = [\"创新\",'创新的','创造力','创造性的','创造','激情','热情的','效率','高效的','卓越','自豪','团队合作','合作','合作的']\n",
    "f1 = open('1.txt','w',encoding='utf-8')\n",
    "for input_word in input_words:\n",
    "    # 为输入词语计算嵌入\n",
    "    input_word_embeddings = get_batch_embedding(input_word, model, tokenizer)\n",
    "    # 为长文本中的词语批量计算嵌入\n",
    "    batch_size = 64  # 可根据GPU内存调整批大小\n",
    "    results = {}\n",
    "    for i in range(0, len(words_in_long_text), batch_size):\n",
    "        batch_words = words_in_long_text[i:i+batch_size]\n",
    "        batch_embeddings = get_batch_embedding(batch_words, model, tokenizer)\n",
    "        for word, embedding in zip(batch_words, batch_embeddings):\n",
    "            similarity = calculate_similarity(input_word_embeddings, embedding.unsqueeze(0))\n",
    "            results[word] = similarity\n",
    "    # 按相似度排序并输出结果\n",
    "    sorted_similar_words = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "    # 输出结果\n",
    "    result = []\n",
    "    resultss = {}\n",
    "    for word, sim in sorted_similar_words[:100]:\n",
    "        result.append([word, str(sim)])\n",
    "        resultss[str(input_word)] = result\n",
    "    f1.write(json.dumps(resultss, ensure_ascii=False) + '\\n')\n",
    "    print(input_word,'\\tdown')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc369e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
